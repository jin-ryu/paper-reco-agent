{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Recommendation Agent - 추론(Inference) 노트북\n",
    "\n",
    "**2025 DATA·AI 분석 경진대회 - 논문·데이터 추천 에이전트**\n",
    "\n",
    "이 노트북은 Qwen3-14B 기반 연구 데이터/논문 추천 시스템의 추론을 수행합니다.\n",
    "\n",
    "## 실행 환경\n",
    "- GPU: NVIDIA RTX 3080 이상 (INT8 양자화 시 14GB VRAM)\n",
    "- CUDA: 11.8+\n",
    "- Python: 3.10+\n",
    "\n",
    "## 실행 순서\n",
    "1. 환경 변수 설정\n",
    "2. 모델 로드\n",
    "3. 추론 실행\n",
    "4. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 프로젝트 루트 경로 추가\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"프로젝트 루트: {project_root}\")\n",
    "\n",
    "# 필수 라이브러리 임포트\n",
    "import asyncio\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv(os.path.join(project_root, '.env'))\n",
    "print(\"✅ 환경 변수 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU 및 CUDA 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 확인\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "    print(f\"사용 가능한 GPU 수: {torch.cuda.device_count()}\")\n",
    "    print(f\"현재 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  GPU를 사용할 수 없습니다. CPU 모드 또는 DEV_MODE로 실행됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 추천 에이전트 초기화\n",
    "\n",
    "**중요**: 이 단계에서 Qwen3-14B 모델이 로드됩니다. GPU 메모리가 충분한지 확인하세요.\n",
    "- INT4: ~8GB VRAM\n",
    "- INT8: ~14GB VRAM\n",
    "- FP16: ~28GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 에이전트 임포트 및 초기화\n",
    "from src.agents.recommendation_agent import KoreanResearchRecommendationAgent\n",
    "from src.config.settings import settings\n",
    "\n",
    "print(\"모델 설정:\")\n",
    "print(f\"  - 모델명: {settings.MODEL_NAME}\")\n",
    "print(f\"  - 양자화: {settings.QUANTIZATION}\")\n",
    "print(f\"  - 임베딩 모델: {settings.EMBEDDING_MODEL}\")\n",
    "print(f\"  - 개발 모드: {settings.DEV_MODE}\")\n",
    "print(\"\\n🚀 에이전트 초기화 중... (수 분 소요될 수 있습니다)\")\n",
    "\n",
    "agent = KoreanResearchRecommendationAgent()\n",
    "\n",
    "print(\"\\n✅ 에이전트 초기화 완료\")\n",
    "print(f\"모델 정보: {json.dumps(agent.llm_model.get_model_info(), indent=2, ensure_ascii=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 테스트 데이터셋 ID 설정\n",
    "\n",
    "DataON에 등록된 실제 데이터셋 ID를 입력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 데이터셋 ID\n",
    "# 예시: KISTI DataON의 실제 데이터셋 ID를 입력하세요\n",
    "test_dataset_id = \"SAMPLE_DATASET_ID\"  # TODO: 실제 데이터셋 ID로 변경\n",
    "\n",
    "print(f\"테스트 데이터셋 ID: {test_dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 추론 실행\n",
    "\n",
    "에이전트가 다음 단계를 수행합니다:\n",
    "1. 소스 데이터셋 메타데이터 조회 (DataON API)\n",
    "2. LLM으로 검색 쿼리 생성\n",
    "3. 후보 수집 (DataON + ScienceON API)\n",
    "4. 하이브리드 유사도 계산 (E5 + BM25)\n",
    "5. LLM으로 최종 추천 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 실행 (비동기)\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"🔍 추천 시작...\\n\")\n",
    "\n",
    "# Jupyter에서 비동기 함수 실행\n",
    "result = await agent.recommend(test_dataset_id)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n✅ 추천 완료! (소요 시간: {elapsed_time:.2f}초)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류 확인\n",
    "if 'error' in result:\n",
    "    print(f\"❌ 오류 발생: {result['error']}\")\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"📊 추천 결과 요약\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n소스 데이터셋:\")\n",
    "    print(f\"  ID: {result['source_dataset']['id']}\")\n",
    "    print(f\"  제목: {result['source_dataset']['title']}\")\n",
    "    print(f\"  키워드: {', '.join(result['source_dataset']['keywords'])}\")\n",
    "    \n",
    "    print(f\"\\n추천 개수: {len(result['recommendations'])}개\")\n",
    "    print(f\"분석 후보: {result['candidates_analyzed']}개\")\n",
    "    print(f\"처리 시간: {result['processing_time_ms']}ms\")\n",
    "    \n",
    "    print(f\"\\n모델 정보:\")\n",
    "    for key, value in result['model_info'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📝 추천 목록\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 목록 상세 출력\n",
    "if 'recommendations' in result:\n",
    "    for rec in result['recommendations']:\n",
    "        print(f\"\\n[{rec['rank']}위] {rec['level']} - {rec['type'].upper()}\")\n",
    "        print(f\"제목: {rec['title']}\")\n",
    "        print(f\"점수: {rec['score']:.3f}\")\n",
    "        print(f\"이유: {rec['reason']}\")\n",
    "        print(f\"URL: {rec['url']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. JSON 파일로 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 JSON 파일로 저장\n",
    "output_dir = os.path.join(project_root, 'data', 'inference_results')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, f\"result_{test_dataset_id}.json\")\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 결과 저장 완료: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 리소스 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 메모리 정리\n",
    "if hasattr(agent, 'llm_model') and agent.llm_model:\n",
    "    agent.llm_model.cleanup()\n",
    "    print(\"✅ 모델 리소스 정리 완료\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"✅ GPU 메모리 캐시 정리 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 추가 테스트 (선택사항)\n",
    "\n",
    "여러 데이터셋에 대해 배치 추론을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 데이터셋 ID 배치 테스트\n",
    "test_dataset_ids = [\n",
    "    \"DATASET_ID_1\",\n",
    "    \"DATASET_ID_2\",\n",
    "    \"DATASET_ID_3\"\n",
    "]\n",
    "\n",
    "batch_results = []\n",
    "\n",
    "for dataset_id in test_dataset_ids:\n",
    "    print(f\"\\n처리 중: {dataset_id}\")\n",
    "    try:\n",
    "        result = await agent.recommend(dataset_id)\n",
    "        batch_results.append({\n",
    "            'dataset_id': dataset_id,\n",
    "            'success': 'error' not in result,\n",
    "            'result': result\n",
    "        })\n",
    "        print(f\"✅ 완료: {len(result.get('recommendations', []))}개 추천\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 실패: {e}\")\n",
    "        batch_results.append({\n",
    "            'dataset_id': dataset_id,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# 배치 결과 저장\n",
    "batch_output_file = os.path.join(output_dir, 'batch_results.json')\n",
    "with open(batch_output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(batch_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ 배치 결과 저장 완료: {batch_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
