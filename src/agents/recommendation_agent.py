import asyncio
import json
import time
import os
from typing import Dict, List, Any
from src.config.settings import settings
from src.tools.research_tools import *
import logging

logger = logging.getLogger(__name__)

class KoreanResearchRecommendationAgent:
    def __init__(self):
        # ê°œë°œ ëª¨ë“œ ê°ì§€ (í™˜ê²½ë³€ìˆ˜ë‚˜ GPU ì—†ìŒ)
        self.dev_mode = (
            os.getenv("DEV_MODE", "false").lower() == "true" or
            not self._check_gpu_available() or
            not self._check_model_requirements()
        )

        if self.dev_mode:
            logger.info("ğŸ­ ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰: Mock ëª¨ë¸ ì‚¬ìš©")
            from src.models.mock_model import MockQwenModel
            self.llm_model = MockQwenModel()
        else:
            logger.info("ğŸš€ í”„ë¡œë•ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰: ì‹¤ì œ Qwen ëª¨ë¸ ì‚¬ìš©")
            from src.models.qwen_model import QwenModel
            self.llm_model = QwenModel()

        self.max_candidates = 20
        self.final_recommendations = 5

    def _check_gpu_available(self) -> bool:
        """GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False

    def _check_model_requirements(self) -> bool:
        """ëª¨ë¸ ë¡œë”©ì— í•„ìš”í•œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        try:
            # ìµœì†Œ ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ í™•ì¸ (ì˜ˆ: 16GB)
            import psutil
            available_memory = psutil.virtual_memory().available / (1024**3)  # GB
            return available_memory > 16
        except ImportError:
            # psutilì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ True ë°˜í™˜
            return True

    async def recommend(self, dataset_id: str) -> Dict[str, Any]:
        """
        ë©”ì¸ ì¶”ì²œ í•¨ìˆ˜

        Args:
            dataset_id: DataON ë°ì´í„°ì…‹ ID

        Returns:
            ì¶”ì²œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()

        try:
            logger.info(f"ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: ë°ì´í„°ì…‹ ID {dataset_id}")

            # 1ë‹¨ê³„: ì†ŒìŠ¤ ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ
            source_data = await self._get_source_data(dataset_id)
            if 'error' in source_data:
                return {"error": f"ì†ŒìŠ¤ ë°ì´í„°ì…‹ ì¡°íšŒ ì‹¤íŒ¨: {source_data['error']}", "recommendations": []}

            # 2ë‹¨ê³„: LLMìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            search_queries = await self._generate_search_queries(source_data)
            logger.info(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: ë°ì´í„°ì…‹({len(search_queries['dataset_queries'])}ê°œ), ë…¼ë¬¸({len(search_queries['paper_queries'])}ê°œ)")

            # 3ë‹¨ê³„: í›„ë³´ ìˆ˜ì§‘
            candidates = await self._collect_candidates_with_queries(search_queries)
            logger.info(f"ì´ {len(candidates)}ê°œ í›„ë³´ ìˆ˜ì§‘ ì™„ë£Œ")

            # 4ë‹¨ê³„: ìœ ì‚¬ë„ ê³„ì‚° ë° ìˆœìœ„ ê²°ì •
            ranked_candidates = await self._rank_candidates(source_data, candidates)
            logger.info(f"ìƒìœ„ {len(ranked_candidates)}ê°œ í›„ë³´ ìˆœìœ„ ê²°ì • ì™„ë£Œ")

            # 5ë‹¨ê³„: LLMì„ ì‚¬ìš©í•œ ìµœì¢… ì¶”ì²œ ìƒì„±
            final_recommendations = await self._generate_final_recommendations(
                source_data, ranked_candidates[:self.max_candidates]
            )

            processing_time = int((time.time() - start_time) * 1000)
            logger.info(f"ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ: {processing_time}ms")

            return {
                "source_dataset": {
                    "id": dataset_id,
                    "title": source_data.get('title_ko', ''),
                    "description": source_data.get('description_ko', '')[:200] + "...",
                    "keywords": source_data.get('keywords', [])
                },
                "recommendations": final_recommendations,
                "processing_time_ms": processing_time,
                "candidates_analyzed": len(candidates),
                "model_info": self.llm_model.get_model_info()
            }

        except Exception as e:
            logger.error(f"ì¶”ì²œ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
            return {
                "error": f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "recommendations": [],
                "processing_time_ms": int((time.time() - start_time) * 1000)
            }

    async def _get_source_data(self, dataset_id: str) -> Dict[str, Any]:
        """1ë‹¨ê³„: ì†ŒìŠ¤ ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ"""
        try:
            source_data = await get_dataon_dataset_metadata(dataset_id)
            logger.info(f"ì†ŒìŠ¤ ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ ì™„ë£Œ: {source_data.get('title_ko', '')}")
            return source_data
        except Exception as e:
            logger.error(f"ì†ŒìŠ¤ ë°ì´í„°ì…‹ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def _generate_search_queries(self, source_data: Dict[str, Any]) -> Dict[str, List[str]]:
        """2ë‹¨ê³„: LLMì„ ì‚¬ìš©í•´ì„œ ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        try:
            # ì œëª©ê³¼ ì„¤ëª… ì„ íƒ (í•œê¸€ ìš°ì„ , ì—†ìœ¼ë©´ ì˜ì–´)
            title = source_data.get('title_ko') or source_data.get('title_en', '')
            description = source_data.get('description_ko') or source_data.get('description_en', '')

            # APIì—ì„œ ê°€ì ¸ì˜¨ ì›ë³¸ í‚¤ì›Œë“œ
            original_keywords = source_data.get('keywords', [])
            keywords_str = ', '.join(original_keywords[:10]) if original_keywords else ''

            # ì–¸ì–´ ì„¤ì • (dataset_main_lang_pc, dataset_sub_lang_pc í•„ë“œ ì°¸ê³ )
            main_lang = source_data.get('dataset_main_lang_pc', 'Korean')
            sub_lang = source_data.get('dataset_sub_lang_pc', 'English')

            # ì–¸ì–´ ë§¤í•‘ (pc -> ì‹¤ì œ ì–¸ì–´ëª…)
            lang_map = {
                'KO': 'Korean',
                'EN': 'English',
                'JA': 'Japanese',
                'ZH': 'Chinese',
                'FR': 'French',
                'DE': 'German',
                'ES': 'Spanish',
                'RU': 'Russian'
            }
            main_lang = lang_map.get(main_lang, main_lang)
            sub_lang = lang_map.get(sub_lang, sub_lang)

            # í”„ë¡¬í”„íŠ¸ ìƒì„± (Qwen3-14B ìµœì í™”)
            prompt = f"""You are a research data search expert. Generate optimal search keywords to find related papers and datasets.

Input Dataset:
Title: {title}
Description: {description[:300]}...
Original Keywords (from API): {keywords_str}
Main Language: {main_lang}
Sub Language: {sub_lang}

Task:
1. Generate 3-5 NEW dataset search keywords (core topics, fields, data types)
2. Generate 3-5 NEW paper search keywords (research methods, theories, techniques)
3. Generate keywords in {main_lang} (main) and {sub_lang} (secondary)
4. DO NOT repeat the original keywords - only generate NEW ones

IMPORTANT: Output ONLY valid JSON. No thinking process, no explanations, no markdown code blocks.

Output this exact JSON structure:
{{"dataset_queries": ["new_kw1", "new_kw2", "new_kw3"], "paper_queries": ["paper_kw1", "paper_kw2", "paper_kw3"]}}"""

            # LLM í˜¸ì¶œ (ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ì‘ë‹µ ìœ ë„)
            response = await self.llm_model.generate(
                prompt,
                max_new_tokens=300,
                temperature=0.1
            )

            # JSON íŒŒì‹±
            try:
                # <think> íƒœê·¸ ì œê±° (Qwen3 thinking ëª¨ë“œ ì¶œë ¥)
                import re
                response_cleaned = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
                response_cleaned = response_cleaned.strip()

                # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ë˜ëŠ” {...} í˜•ì‹)
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_cleaned, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    json_match = re.search(r'\{.*\}', response_cleaned, re.DOTALL)
                    json_str = json_match.group(0) if json_match else response_cleaned

                queries = json.loads(json_str)

                # LLMì´ ìƒì„±í•œ ìƒˆ í‚¤ì›Œë“œ
                llm_dataset_queries = queries.get('dataset_queries', [])
                llm_paper_queries = queries.get('paper_queries', [])

                # ì›ë³¸ í‚¤ì›Œë“œ + LLM ìƒì„± í‚¤ì›Œë“œ ë³‘í•© (ì¤‘ë³µ ì œê±°)
                def merge_and_dedupe(original: List[str], new_keywords: List[str], max_count: int = 10) -> List[str]:
                    """í‚¤ì›Œë“œ ë³‘í•© ë° ì¤‘ë³µ ì œê±° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)"""
                    result = []
                    seen = set()

                    # ì›ë³¸ í‚¤ì›Œë“œ ì¶”ê°€
                    for kw in original:
                        kw_clean = kw.strip()
                        kw_lower = kw_clean.lower()
                        if kw_clean and kw_lower not in seen:
                            result.append(kw_clean)
                            seen.add(kw_lower)

                    # ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€
                    for kw in new_keywords:
                        kw_clean = kw.strip()
                        kw_lower = kw_clean.lower()
                        if kw_clean and kw_lower not in seen:
                            result.append(kw_clean)
                            seen.add(kw_lower)

                    return result[:max_count]

                # ë°ì´í„°ì…‹/ë…¼ë¬¸ ì¿¼ë¦¬ ìƒì„± (ì¤‘ë³µ ì œê±°ë¨)
                dataset_queries = merge_and_dedupe(original_keywords, llm_dataset_queries, 10)
                paper_queries = merge_and_dedupe(original_keywords, llm_paper_queries, 10)

                # ë¹„ì–´ìˆìœ¼ë©´ í´ë°±
                if not dataset_queries or not paper_queries:
                    raise ValueError("Empty queries generated")

                logger.info(f"ìµœì¢… í‚¤ì›Œë“œ - ë°ì´í„°ì…‹: {dataset_queries}")
                logger.info(f"ìµœì¢… í‚¤ì›Œë“œ - ë…¼ë¬¸: {paper_queries}")
                logger.info(f"  (ì›ë³¸: {len(original_keywords)}ê°œ, LLM ì¶”ê°€: ë°ì´í„°ì…‹ {len(llm_dataset_queries)}ê°œ, ë…¼ë¬¸ {len(llm_paper_queries)}ê°œ)")
                return {
                    'dataset_queries': dataset_queries,
                    'paper_queries': paper_queries
                }

            except (json.JSONDecodeError, ValueError, AttributeError) as e:
                logger.warning(f"LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
                logger.warning(f"LLM ì›ë³¸ ì‘ë‹µ:\n{response}")
                # í´ë°±: ê¸°ì¡´ í‚¤ì›Œë“œ ë˜ëŠ” ì¶”ì¶œ
                fallback_keywords = source_data.get('keywords', [])
                if not fallback_keywords:
                    text = f"{title} {description}"
                    fallback_keywords = extract_keywords_from_text(text)

                return {
                    'dataset_queries': fallback_keywords[:5],
                    'paper_queries': fallback_keywords[:5]
                }

        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ì¡´ í‚¤ì›Œë“œ
            fallback_keywords = source_data.get('keywords', ['research', 'data'])[:5]
            return {
                'dataset_queries': fallback_keywords,
                'paper_queries': fallback_keywords
            }

    async def _collect_candidates_with_queries(self, search_queries: Dict[str, List[str]]) -> List[Dict[str, Any]]:
        """3ë‹¨ê³„: ìƒì„±ëœ ì¿¼ë¦¬ë¡œ í›„ë³´ ìˆ˜ì§‘ (DataON + ScienceON)"""
        candidates = []

        try:
            # ë³‘ë ¬ë¡œ í›„ë³´ ìˆ˜ì§‘
            tasks = [
                self._search_similar_datasets(search_queries['dataset_queries']),
                self._search_related_papers(search_queries['paper_queries'])
            ]

            results = await asyncio.gather(*tasks, return_exceptions=True)

            # DataON ë°ì´í„°ì…‹ í›„ë³´
            if not isinstance(results[0], Exception):
                for dataset in results[0]:
                    candidates.append({
                        'type': 'dataset',
                        'source': 'dataon',
                        'data': dataset,
                        'title': dataset.get('title_ko', ''),
                        'description': dataset.get('description_ko', ''),
                        'keywords': dataset.get('keywords', []),
                        'url': dataset.get('url', ''),
                        'combined_text': dataset.get('combined_text', '')
                    })

            # ScienceON ë…¼ë¬¸ í›„ë³´
            if not isinstance(results[1], Exception):
                for paper in results[1]:
                    candidates.append({
                        'type': 'paper',
                        'source': 'scienceon',
                        'data': paper,
                        'title': paper.get('title', ''),
                        'description': paper.get('abstract', '')[:200] if paper.get('abstract') else '',
                        'keywords': paper.get('keywords', '').split(',') if paper.get('keywords') else [],
                        'url': paper.get('content_url', ''),
                        'combined_text': paper.get('combined_text', ''),
                        'cn': paper.get('cn', '')
                    })

            return candidates

        except Exception as e:
            logger.error(f"í›„ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    async def _search_similar_datasets(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """DataONì—ì„œ ìœ ì‚¬í•œ ë°ì´í„°ì…‹ ê²€ìƒ‰"""
        try:
            return await search_similar_dataon_datasets(keywords, limit=15)
        except Exception as e:
            logger.error(f"DataON ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def _search_related_papers(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """ScienceONì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰"""
        try:
            papers = []
            # í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰í•˜ì—¬ ë‹¤ì–‘ì„± í™•ë³´
            for keyword in keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                keyword_papers = await search_scienceon_papers(keyword, limit=5)
                papers.extend(keyword_papers)

            # ì¤‘ë³µ ì œê±° (CN ê¸°ì¤€)
            seen_cns = set()
            unique_papers = []
            for paper in papers:
                cn = paper.get('cn', '')
                if cn and cn not in seen_cns:
                    seen_cns.add(cn)
                    unique_papers.append(paper)

            return unique_papers[:15]  # ìµœëŒ€ 15ê°œ

        except Exception as e:
            logger.error(f"ScienceON ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def _rank_candidates(self, source_data: Dict[str, Any], candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """3ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚° ë° í›„ë³´ ìˆœìœ„ ê²°ì •"""
        try:
            source_text = source_data.get('combined_text', '')

            # ê° í›„ë³´ì˜ í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚°
            scored_candidates = []
            for candidate in candidates:
                try:
                    candidate_text = candidate.get('combined_text', '')

                    # ğŸš€ BM25 + ì„ë² ë”© í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚°
                    from tools.research_tools import calculate_hybrid_similarity
                    hybrid_result = calculate_hybrid_similarity(source_text, candidate_text)

                    similarity_score = hybrid_result['final_score']  # í•˜ì´ë¸Œë¦¬ë“œ ìµœì¢… ì ìˆ˜ ì‚¬ìš©

                    # ìµœì¢… ì ìˆ˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    # (ê²€ìƒ‰ API ì‘ë‹µì— ì´ë¯¸ ì¸ìš© ì •ë³´ í¬í•¨ë¨, ìƒì„¸ ì¡°íšŒ ë¶ˆí•„ìš”)
                    final_score = similarity_score

                    candidate.update({
                        'similarity_score': similarity_score,
                        'semantic_score': hybrid_result['semantic_score'],
                        'lexical_score': hybrid_result['lexical_score'],
                        'final_score': final_score,
                        'common_keywords': hybrid_result.get('common_keywords', [])
                    })

                    scored_candidates.append(candidate)

                except Exception as e:
                    logger.warning(f"í›„ë³´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    continue

            # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
            ranked_candidates = sorted(scored_candidates, key=lambda x: x['final_score'], reverse=True)
            return ranked_candidates

        except Exception as e:
            logger.error(f"í›„ë³´ ìˆœìœ„ ê²°ì • ì‹¤íŒ¨: {e}")
            return candidates

    async def _generate_final_recommendations(self, source_data: Dict[str, Any], top_candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """4ë‹¨ê³„: Qwen ëª¨ë¸ì„ ì‚¬ìš©í•œ ìµœì¢… ì¶”ì²œ ìƒì„±"""
        try:
            # LLMìš© ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context = {
                'source_title': source_data.get('title_ko', ''),
                'source_description': source_data.get('description_ko', ''),
                'source_keywords': ', '.join(source_data.get('keywords', [])),
                'source_classification': source_data.get('classification_ko', ''),
                'candidates': top_candidates
            }

            # Qwen ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
            task_description = f"""
ì£¼ì–´ì§„ ì†ŒìŠ¤ ë°ì´í„°ì…‹ê³¼ ê´€ë ¨ëœ ì—°êµ¬ë…¼ë¬¸ê³¼ ë°ì´í„°ì…‹ì„ {self.final_recommendations}ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”.
ê° ì¶”ì²œì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ë…¼ë¦¬ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•˜ê³ , ì¶”ì²œ ìˆ˜ì¤€ì„ ê²°ì •í•´ì£¼ì„¸ìš”.
"""

            prompt = self.llm_model.create_korean_prompt(task_description, context)

            # LLM í˜¸ì¶œ (ìµœëŒ€ 2íšŒ ì¬ì‹œë„)
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    logger.info(f"LLM ì¶”ì²œ ìƒì„± ì‹œë„ {attempt + 1}/{max_retries}")
                    response = await self.llm_model.generate(prompt)

                    # JSON ì‘ë‹µ íŒŒì‹±
                    recommendations = self._parse_llm_response(response, top_candidates)

                    if recommendations:
                        return recommendations
                    else:
                        logger.warning(f"LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            # í”„ë¡¬í”„íŠ¸ ìˆ˜ì •í•˜ì—¬ ì¬ì‹œë„
                            prompt = self._create_simplified_prompt(source_data, top_candidates)
                            logger.info("ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„")
                            continue
                        else:
                            logger.error("ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨, ì¶”ì²œ ìƒì„± ë¶ˆê°€")
                            return []

                except Exception as e:
                    logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                    if attempt == max_retries - 1:
                        return []

            return []

        except Exception as e:
            logger.error(f"ìµœì¢… ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    def _parse_llm_response(self, response: str, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ì¶”ì²œ ê²°ê³¼ ìƒì„±"""
        try:
            import re

            # <think> íƒœê·¸ ì œê±° (Qwen3 thinking ëª¨ë“œ ì¶œë ¥)
            # ë¹ˆ íƒœê·¸ì™€ ë‚´ìš©ì´ ìˆëŠ” íƒœê·¸ ëª¨ë‘ ì œê±°
            response_cleaned = re.sub(r'<think>\s*</think>', '', response, flags=re.DOTALL)
            response_cleaned = re.sub(r'<think>.*?</think>', '', response_cleaned, flags=re.DOTALL)
            response_cleaned = response_cleaned.strip()

            # JSON ì‹œì‘ ë¶€ë¶„ê¹Œì§€ ëª¨ë“  í…ìŠ¤íŠ¸ ì œê±° (ë” ê³µê²©ì )
            if '{' in response_cleaned:
                json_start_idx = response_cleaned.find('{')
                response_cleaned = response_cleaned[json_start_idx:]

            # 1. JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ë˜ëŠ” { ... })
            # ê°€ì¥ ë°”ê¹¥ìª½ ì¤‘ê´„í˜¸ ìŒ ì°¾ê¸° (ì¤‘ì²© ì§€ì›)
            json_match = re.search(r'```json\s*(\{.*\})\s*```', response_cleaned, re.DOTALL)
            if not json_match:
                # JSON ë¸”ë¡ ë§ˆì»¤ ì—†ì´ ì°¾ê¸°
                json_match = re.search(r'\{(?:[^{}]|(?:\{(?:[^{}]|\{[^{}]*\})*\}))*\}', response_cleaned, re.DOTALL)

            if json_match:
                json_str = json_match.group(1) if json_match.lastindex else json_match.group(0)

                # JSON ì •ë¦¬ (í”í•œ ì˜¤ë¥˜ ìˆ˜ì •)
                json_str = json_str.strip()

                # ì£¼ì„ ì œê±° (// ... ë˜ëŠ” ... // ...)
                json_str = re.sub(r'//.*?(?=\n|$)', '', json_str)
                json_str = re.sub(r',\s*\.\.\.', '', json_str)  # , ... íŒ¨í„´ ì œê±°

                # í›„í–‰ ì‰¼í‘œ ì œê±°
                json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)

                # ë‹¨ì¼ ë”°ì˜´í‘œë¥¼ ì´ì¤‘ ë”°ì˜´í‘œë¡œ (ë‹¨, ë¬¸ìì—´ ë‚´ë¶€ ì•„ë‹Œ ê²½ìš°ë§Œ)
                # json_str = json_str.replace("'", '"')  # ë„ˆë¬´ ê³µê²©ì , ì œê±°

                # ì˜ëª»ëœ ë°°ì—´ í™•ì¥ í‘œì‹œ ì œê±° (ì˜ˆ: ["item1", ...])
                json_str = re.sub(r',\s*\.\.\.\s*\]', ']', json_str)

                logger.debug(f"ì •ë¦¬ëœ JSON:\n{json_str[:500]}...")

                # ì´ì˜ê²Œ í¬ë§·íŒ…í•´ì„œ ë¡œê¹…
                try:
                    temp_parsed = json.loads(json_str)
                    logger.info(f"ì¶”ì¶œëœ JSON:\n{json.dumps(temp_parsed, indent=2, ensure_ascii=False)}")
                except:
                    logger.info(f"ì¶”ì¶œëœ JSON (raw):\n{json_str[:1000]}...")

                try:
                    parsed_response = json.loads(json_str)
                    logger.info(f"âœ… JSON íŒŒì‹± ì„±ê³µ")
                    logger.info(f"íŒŒì‹±ëœ íƒ€ì…: {type(parsed_response)}, í‚¤: {parsed_response.keys() if isinstance(parsed_response, dict) else 'N/A'}")
                except json.JSONDecodeError as e:
                    logger.warning(f"JSON íŒŒì‹± 1ì°¨ ì‹¤íŒ¨: {e}, ìˆ˜ì • ì‹œë„ ì¤‘...")
                    logger.warning(f"ì‹¤íŒ¨í•œ JSON ì•ë¶€ë¶„:\n{json_str[:300]}")
                    # ë” ê³µê²©ì ì¸ ì •ë¦¬
                    json_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str)  # ì œì–´ ë¬¸ì ì œê±°
                    json_str = re.sub(r'\\(?!["\\/bfnrtu])', r'\\\\', json_str)  # ì˜ëª»ëœ ì´ìŠ¤ì¼€ì´í”„ ìˆ˜ì •
                    # ë§ˆì§€ë§‰ ì‹œë„: ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ì ì œê±°
                    json_str = re.sub(r'[^\x20-\x7E\u0080-\uFFFF{}[\]":,.\-+0-9]', '', json_str)
                    try:
                        parsed_response = json.loads(json_str)
                        logger.info(f"âœ… JSON íŒŒì‹± ì„±ê³µ (2ì°¨ ì‹œë„)")
                    except json.JSONDecodeError as e2:
                        logger.error(f"âŒ JSON íŒŒì‹± 2ì°¨ ì‹¤íŒ¨: {e2}")
                        logger.error(f"ì •ë¦¬ í›„ JSON:\n{json_str[:300]}")
                        raise

                # parsed_responseê°€ ë°°ì—´ì¸ ê²½ìš° ì²˜ë¦¬
                if isinstance(parsed_response, list):
                    logger.warning(f"âš ï¸  ì‘ë‹µì´ ë°°ì—´ì…ë‹ˆë‹¤. ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©")
                    if len(parsed_response) > 0:
                        parsed_response = parsed_response[0]

                if isinstance(parsed_response, dict) and 'recommendations' in parsed_response:
                    logger.info(f"recommendations í‚¤ ë°œê²¬, {len(parsed_response['recommendations'])}ê°œ í•­ëª©")
                    llm_recommendations = parsed_response['recommendations']

                    # LLM ì‘ë‹µê³¼ í›„ë³´ ë°ì´í„° ë§¤ì¹­
                    final_recommendations = []
                    for idx, rec in enumerate(llm_recommendations[:self.final_recommendations]):
                        candidate_number = rec.get('candidate_number', 0)
                        logger.debug(f"ì²˜ë¦¬ ì¤‘: ìˆœì„œ={idx+1}, candidate_number={candidate_number}")

                        if 1 <= candidate_number <= len(candidates):
                            candidate = candidates[candidate_number - 1]

                            # LLM ì¶”ì²œ ì •ë³´ì™€ í›„ë³´ ë°ì´í„° ê²°í•©
                            # rankëŠ” ì¶”ì²œ ìˆœì„œ (1ë¶€í„° ì‹œì‘)
                            # title, type, score, urlì€ ëª¨ë‘ candidatesì—ì„œ ê°€ì ¸ì˜´
                            # reason, levelë§Œ LLMì´ ìƒì„±
                            final_rec = {
                                "rank": idx + 1,  # ì¶”ì²œ ìˆœì„œ (LLMì´ ë°˜í™˜í•œ ìˆœì„œ)
                                "type": candidate['type'],
                                "title": candidate['title'],
                                "description": candidate['description'][:200] + "..." if len(candidate.get('description', '')) > 200 else candidate.get('description', ''),
                                "score": candidate.get('final_score', 0.5),  # E5 ê³„ì‚°í•œ ì ìˆ˜ ì‚¬ìš©
                                "reason": rec.get('reason', 'ì¶”ì²œ ì´ìœ  ìƒì„± ì‹¤íŒ¨'),
                                "level": rec.get('level', 'ì°¸ê³ '),
                                "url": candidate['url']
                            }
                            final_recommendations.append(final_rec)
                            logger.debug(f"âœ… ì¶”ì²œ í•­ëª© ì¶”ê°€: {candidate['title'][:50]}")
                        else:
                            logger.warning(f"âš ï¸  ì˜ëª»ëœ candidate_number: {candidate_number} (ì´ {len(candidates)}ê°œ)")

                    # ì´ë¯¸ ìˆœì„œëŒ€ë¡œ ì¶”ê°€ë˜ì—ˆìœ¼ë¯€ë¡œ ì •ë ¬ ë¶ˆí•„ìš”
                    # final_recommendations.sort(key=lambda x: x['rank'])

                    if final_recommendations:
                        logger.info(f"âœ… LLM ì¶”ì²œ ìƒì„± ì„±ê³µ: {len(final_recommendations)}ê°œ")
                        return final_recommendations
                    else:
                        logger.warning(f"âš ï¸  ë§¤ì¹­ëœ ì¶”ì²œ í•­ëª© ì—†ìŒ (LLM ì‘ë‹µ {len(llm_recommendations)}ê°œ)")
                else:
                    logger.warning(f"âš ï¸  'recommendations' í‚¤ê°€ ì‘ë‹µì— ì—†ìŒ. í‚¤ ëª©ë¡: {list(parsed_response.keys())}")

            # JSON íŒŒì‹± ì‹¤íŒ¨
            logger.warning(f"LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ì‹¤íŒ¨, ì›ë¬¸:\n{response[:500]}...")
            return []

        except Exception as e:
            logger.error(f"LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"LLM ì‘ë‹µ:\n{response[:1000]}...")
            return []

    def _create_simplified_prompt(self, source_data: Dict[str, Any], candidates: List[Dict[str, Any]]) -> str:
        """
        ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì¬ì‹œë„ìš©)
        ë” ëª…í™•í•˜ê³  ê°„ë‹¨í•œ ì§€ì‹œì‚¬í•­
        """
        # ìƒìœ„ 5ê°œ í›„ë³´ë§Œ ì‚¬ìš©
        top_5 = candidates[:5]

        candidates_text = ""
        for i, cand in enumerate(top_5, 1):
            candidates_text += f"\n[{i}] {cand.get('type', 'unknown')}: {cand.get('title', '')} (ìœ ì‚¬ë„: {cand.get('final_score', 0):.2f})\n"

        prompt = f"""Select 3-5 best recommendations and output as JSON ONLY. Do NOT use <think> tags.

Source Dataset: {source_data.get('title_ko') or source_data.get('title_en', '')}

Candidates:
{candidates_text}

Output this JSON structure exactly (start with '{{' character):
{{
  "recommendations": [
    {{"candidate_number": 1, "reason": "Very high similarity", "level": "ê°•ì¶”"}},
    {{"candidate_number": 2, "reason": "High similarity", "level": "ì¶”ì²œ"}},
    {{"candidate_number": 3, "reason": "Related topic", "level": "ì°¸ê³ "}}
  ]
}}

Rules:
- Only output: candidate_number (1-5), reason, level
- DO NOT output: rank, title, type, score
- Start your response with '{{' now:"""

        return prompt

    def _generate_fallback_recommendations(self, source_data: Dict[str, Any], candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        í´ë°±: ê°„ë‹¨í•œ ì ìˆ˜ ê¸°ë°˜ ì¶”ì²œ ìƒì„± (ì‚¬ìš© ì•ˆí•¨ - ì œê±° ì˜ˆì •)
        """
        logger.warning("í´ë°± í•¨ìˆ˜ í˜¸ì¶œë¨ - ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šì•„ì•¼ í•¨")
        recommendations = []

        for idx, candidate in enumerate(candidates[:self.final_recommendations], 1):
            try:
                score = candidate.get('final_score', 0.5)

                # ê°„ë‹¨í•œ ë ˆë²¨ ê²°ì •
                if score >= 0.8:
                    level = "ê°•ì¶”"
                elif score >= 0.65:
                    level = "ì¶”ì²œ"
                else:
                    level = "ì°¸ê³ "

                # ê°„ë‹¨í•œ ì¶”ì²œ ì´ìœ 
                reason = f"ìœ ì‚¬ë„ ì ìˆ˜ {score:.2f} (ì˜ë¯¸ì  {candidate.get('semantic_score', 0.0):.2f}, ì–´íœ˜ì  {candidate.get('lexical_score', 0.0):.2f})"

                recommendation = {
                    "rank": idx,
                    "type": candidate['type'],
                    "title": candidate['title'],
                    "description": candidate['description'][:100] + "..." if len(candidate.get('description', '')) > 100 else candidate.get('description', ''),
                    "score": round(score, 2),
                    "reason": reason,
                    "level": level,
                    "url": candidate['url']
                }
                recommendations.append(recommendation)

            except Exception as e:
                logger.warning(f"í´ë°± ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
                continue

        return recommendations